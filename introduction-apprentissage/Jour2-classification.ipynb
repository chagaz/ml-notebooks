{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à l'apprentissage automatique - Jour 2 - Classification\n",
    "\n",
    "Dans ce notebook, vous allez apprendre à étudier un problème de classification\n",
    "    \n",
    "Ce notebook a été créé par [Chloé-Agathe Azencott](http://cazencott.info).\n",
    "\n",
    "Ce noteboook utilise les librairies suivantes :\n",
    "* python 3.4.3\n",
    "* numpy 1.15.0\n",
    "* matplotlib 2.2.2\n",
    "* scikit-learn 0.19.2\n",
    "\n",
    "Pour vérifier quelles versions de ces librairies vous utilisez, faites tourner la cellue ci-dessous en cliquant dessus puis en cliquant sur le bouton \"Play\" dans le menu au-dessus de cette fenêtre, ou en tapant Shift+Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "import numpy\n",
    "print(numpy.__version__)\n",
    "\n",
    "import matplotlib\n",
    "print(matplotlib.__version__)\n",
    "\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Le problème du jour\n",
    "\n",
    "Notre but aujourd'hui est d'utiliser la description visuelle d'un champignon pour prédire s'il est comestible ou non. \n",
    "\n",
    "Les données sont disponibles dans `data/mushrooms.csv`. Elles sont issues du jeu de données https://archive.ics.uci.edu/ml/datasets/Mushroom mais légèrement modifiées.\n",
    "\n",
    "Vous pouvez commencer par l'ouvrir avec un éditeur de texte, ou un logiciel tableur, ou en ligne de commande avec la commande less. \n",
    "\n",
    "Il contient une première ligne (header) décrivant les colonnes, puis une ligne par champignon. Les valeurs des différentes variables sont toutes représentées par des lettres ; en voici la signification :\n",
    "1. cap-shape: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\n",
    "2. cap-surface: fibrous=f,grooves=g,scaly=y,smooth=s\n",
    "3. cap-color: brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y\n",
    "4. bruises?: bruises=t,no=f\n",
    "5. odor: almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s\n",
    "6. gill-attachment: attached=a,descending=d,free=f,notched=n\n",
    "7. gill-spacing: close=c,crowded=w,distant=d\n",
    "8. gill-size: broad=b,narrow=n\n",
    "9. gill-color: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e, white=w,yellow=y\n",
    "10. stalk-shape: enlarging=e,tapering=t\n",
    "11. stalk-root: bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=?\n",
    "12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\n",
    "14. stalk-color-above-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\n",
    "15. stalk-color-below-ring: brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\n",
    "16. veil-type: partial=p,universal=u\n",
    "17. veil-color: brown=n,orange=o,white=w,yellow=y\n",
    "18. ring-number: none=n,one=o,two=t\n",
    "19. ring-type: cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z\n",
    "20. spore-print-color: black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y\n",
    "21. population: abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y\n",
    "22. habitat: grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods=d\n",
    "\n",
    "La première colomne nous informe de la classe de chaque champignong, 'e' pour comestible (edible) et 'p' pour vénéneux (poisonous)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Mise en place du cadre de travail\n",
    "\n",
    "Nous allons maintenant mettre en place notre cadre de travail. Plusieurs de ces étapes sont semblables à celles que nous avons suivies hier pour la régression et nous ne les détaillons pas ici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Charger les librairies de science des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Charger les données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/mushrooms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Convertir les variables en valeurs numériques \n",
    "\n",
    "Nos variables sont pour l'instant catégorielles. Par exemple, pour la variable \"forme du chapeau\" (`cap shape`), `b` correspond à un chapeau campanulé (bell cap), `c` à un chapeau conique (conical cap), `f` à un chapeau plat (flat cap), `k` à un chapeau papillé (knobbed cap), `s` à un chapeau déprimé (sunken cap), and `x` à un chapeau convexe. \n",
    "\n",
    "Pour travailler avec ces données, il nous faut convertir ces catégories en valeurs numériques. Aujourd'hui, nous allons simplement convertir chaque lettre en un nombre entre 0 et le nombre total de catégorie, grâce à [preprocessing.LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html).\n",
    "\n",
    "Cet encodage n'est pas nécessairement idéal : un algorithme qui utilise la distance euclidienne va considérer qu'un chapeau convexe (`x` converti en 5) est plus proche d'un chapeau déprimé (`s` converti en 4) que d'un chapeau conique (`c` converti en 1), ce qui n'a pas beaucoup de sens. L'encodage [one-hot](http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features) pourrait être un meilleur choix. Cependant, il a l'inconvénient d'augmenter le nombre de variables, et de créer des variables corrélées. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col] = labelencoder.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons de nouveau observer nos données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Créer le cadre de sélection et d'évaluation de modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraire X et y du dataframe df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df.iloc[:, 1:]) # exclude first column\n",
    "y = np.array(df.iloc[:, 0])  # first column only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 1 :__ Combien d'échantillons (examples) notre jeu de données contient-il ? Combien de variables ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparer les données en un jeu d'entraînement et un de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    model_selection.train_test_split(X, y,\n",
    "                                    test_size=0.3 # 30% des données dans le jeu de test\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2 :__ Combien d'échantillons (examples) le jeu d'entraînement contient-il ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mettre en place une validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "# Créer un objet KFold qui permettra de cross-valider en 5 folds\n",
    "kf = model_selection.KFold(n_splits=5,  # 5 folds\n",
    "                           shuffle=True # mélanger les échantillons avant de créer les folds\n",
    "                          )\n",
    "\n",
    "# Utiliser kf pour partager le jeu d'entraînement en 5 folds. \n",
    "# kf.split retourne un iterateur (consommé après une boucle).\n",
    "# Pour pouvoir se servir plusieurs fois des mêmes folds, nous transformons cet itérateur en liste d'indices :\n",
    "kf_indices = list(kf.split(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix du critère de sélection de modèle \n",
    "\n",
    "De nombreux critères de sélection de modèle sont à notre disposition pour les problèmes de classification. (Voir http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter.) Aujourd'hui, nous allons utiliser le [score F1](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 3 :__ Pourquoi choisir le score F1 ? Quelle autre critère pourrait être approprié ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Régression logistique \n",
    "\n",
    "Nous allons utiliser [l'implementation scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) de la régression logistique, qui contient un paramètre de régularisation C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Régression logistique non régularisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 3 :__ Pour utiliser une régression logistique très peu régularisée, faut-il choisir une grande valeur ou une faible valeur de C ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant calculer le score F1 moyen, en validation croisée sur le jeu d'entraînement, d'une régression logistique très peu régularisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Créer un modèle de régression logistique \n",
    "model_logreg = linear_model.LogisticRegression(C=1e10)\n",
    "\n",
    "# L'évaluer en validation croisée\n",
    "f1_logreg = model_selection.cross_val_score(model_logreg, # modèle à entraîner\n",
    "                                            X_train, y=y_train, # jeu d'entrainement\n",
    "                                            scoring='f1', # score à utiliser\n",
    "                                            cv=kf_indices # validation croisée à utiliser\n",
    "                                            )\n",
    "\n",
    "# Afficher le F1 moyen\n",
    "print(\"F1 de la régression logistique : %.3f +/- %.3f\" % (np.mean(f1_logreg), # moyenne\n",
    "                                                         np.std(f1_logreg) # écart-type\n",
    "                                                        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 4 :__ Ce score vous parait-il bon ? Mauvais ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons aussi visualiser les coefficients affectés à chacune des variables dans la régression logistique. Pour cela, nous commençons par ré-entrainer une régression logistique sur l'intégralité du jeu d'entraînement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer une régression logistique sur l'ensemble du jeu d'entrainement\n",
    "model_logreg.fit(X_train, y_train)\n",
    "\n",
    "fig = plt.figure(figsize(12, 6))\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "plt.scatter(range(num_features), model_logreg.coef_)\n",
    "\n",
    "plt.xlabel('Variables', fontsize=14)\n",
    "feature_names = list(df.columns[1:])\n",
    "tmp = plt.xticks(range(num_features), feature_names, \n",
    "                 rotation=90, fontsize=14)\n",
    "tmp = plt.ylabel('Poids', fontsize=14)\n",
    "\n",
    "tmp = plt.title('Coefficients de la regression logistique', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mieux comparer ces poids, nous pouvons aussi afficher leurs valeurs absolues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize(12, 6))\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "plt.scatter(range(num_features), np.abs(model_logreg.coef_))\n",
    "\n",
    "plt.xlabel('Variables', fontsize=14)\n",
    "feature_names = list(df.columns[1:])\n",
    "tmp = plt.xticks(range(num_features), feature_names, \n",
    "                 rotation=90, fontsize=14)\n",
    "tmp = plt.ylabel('Poids', fontsize=14)\n",
    "\n",
    "tmp = plt.title('Coefficients (valeur absolue) de la regression logistique', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 5 :__ Quelles variables vous paraissent les plus utiles pour prédire si un champignon est comestible ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Régression logistique régularisée l1\n",
    "\n",
    "Certaines des variables ont un poids très proche de 0 dans notre régression logistique. Une régularisation l1 permettrait de ramener les poids correspondant à 0, et d'éliminer ces variables.\n",
    "\n",
    "Nous allons reprendre exactement le code utilisé hier pour le lasso, pour observer l'évolution du modèle de classification appris par une régression logistique régularisée l1 en fonction du coefficient de régularisation. Attention, nous devons remplacer `alpha` par `C`, et le critère d'évaluation (MSE) par le score F1.\n",
    "\n",
    "\n",
    "Nous allons aussi utiliser la [commande magique time](https://ipython.readthedocs.io/en/stable/interactive/magics.html) pour mesurer le temps de calcul d'une cellule de notre notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Commande magique pour chronométrer le temps d'exécution\n",
    "\n",
    "# Définir une grille de valeurs pour le coefficient de régularisation :\n",
    "cvalues = np.logspace(-3, 1, 10)\n",
    "\n",
    "f1_per_cval_lasso = [] # pour enregistrer les valeurs de F1 pour chacune des 20 valeurs de C\n",
    "weights_per_cval_lasso = [] # pour enregistrer les coefficients associés à chaque variable,  \n",
    "                       # pour les 10 valeurs de C\n",
    "for cval in cvalues:\n",
    "    # Créer un modèle de régression ridge\n",
    "    model_lasso = linear_model.LogisticRegression(penalty='l1', C=cval)\n",
    "    \n",
    "    # Calculer la performance en validation croisée du modèle\n",
    "    f1 = model_selection.cross_val_score(model_lasso, \n",
    "                                           X_train, y=y_train, \n",
    "                                           scoring='f1', \n",
    "                                           cv=kf_indices)\n",
    "    f1_per_cval_lasso.append(f1)\n",
    "    \n",
    "    # Entrainer le modèle sur le jeu d'entrainement total \n",
    "    model_lasso.fit(X_train, y_train)\n",
    "    \n",
    "    # Enregistrer les coefficients de régression \n",
    "    weights_per_cval_lasso.append(model_lasso.coef_)\n",
    "\n",
    "# Convertir weights_per_cval_lasso en un array aux bonnes dimensions\n",
    "weights_per_cval_lasso = np.array(weights_per_cval_lasso)\n",
    "weights_per_cval_lasso = np.reshape(weights_per_cval_lasso, (weights_per_cval_lasso.shape[0], \n",
    "                                                             weights_per_cval_lasso.shape[-1]))\n",
    "    \n",
    "plt.errorbar(cvalues, # abcisse\n",
    "             np.mean(np.array(f1_per_cval_lasso), axis=1), # ordonnée : MSE moyenne\n",
    "             yerr=np.std(np.array(f1_per_cval_lasso), axis=1)/np.sqrt(5) # barre d'erreur verticale\n",
    "            )\n",
    "plt.xscale('log') # utiliser une échelle logarithmique en abcisse\n",
    "\n",
    "# Étiqueter les axes\n",
    "tmp = plt.xlabel('Valeur de C', fontsize=14)\n",
    "tmp = plt.ylabel('F1 moyen', fontsize=14)\n",
    "\n",
    "# Titre\n",
    "tmp = plt.title(\"Regression logistique regularisee l1\", fontsize=14)\n",
    "\n",
    "# Créer une figure\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "\n",
    "lines = plt.plot(cvalues, # abcisse = valeurs de alpha\n",
    "                 weights_per_cval_lasso # ordonnée = valeurs des coefficients de régression\n",
    "                ) \n",
    "plt.xscale('log') # échelle logarithmique en abcisse\n",
    "\n",
    "# Afficher la légende\n",
    "tmp = plt.legend(lines, # récupérer l'identifiant \n",
    "                 list(df.columns[1:]), # nom de chaque variable\n",
    "                 frameon=False, # pas de cadre autour de la légende\n",
    "                 loc=(1, 0),  # placer la légende à droite de l'image\n",
    "                 fontsize=14)\n",
    "\n",
    "tmp = plt.xlabel('Valeur de C', fontsize=14)\n",
    "tmp = plt.ylabel('Coefficient', fontsize=14)\n",
    "\n",
    "tmp = plt.title('Regression logistique regularisee l1', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 6 :__ La régularisation l1 permet-elle d'améliorer la performance de la régression logistique ? Cela vous surprend-il ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 7 :__ Quelles vous paraissent être les variables les plus importantes pour prédire si un champignon est comestible ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plutôt que de manipuler nous mêmes la validation croisée pour toutes les valeurs d'hyperparamètre, si nous cherchons uniquement à sélectionner le meilleur modèle (et non pas à examiner chacun des modèles comme nous l'avons fait jusqu'à présent), il est possible d'utiliser la fonction [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) du module `model_selection` de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# Définir une grille d'hyperparamètres\n",
    "param_grid = {'C': cvalues}\n",
    "\n",
    "# Definir un modèle de recherche sur grille pour une régression logistique pénalisée l1\n",
    "model_ridge = model_selection.GridSearchCV(linear_model.LogisticRegression(penalty='l1'),\n",
    "                                         param_grid, \n",
    "                                         scoring='f1', \n",
    "                                         cv=kf_indices)\n",
    "\n",
    "# Entraîner le modèle\n",
    "model_ridge.fit(X_train, y_train)\n",
    "\n",
    "# Meilleure valeur d'hyperparamètre\n",
    "print(\"C optimal :\", model_ridge.best_params_)\n",
    "\n",
    "# Performance du meilleur modèle\n",
    "print(\"F1 moyenne : %.3f\" % model_ridge.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 8 :__ Les résultats vous paraissent-ils compatible avec l'expérience précédente, ou nous avions affiché le score F1 de chacun des modèles ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 9 :__ Comparer le temps d'exécution de ce code à celui que nous avions écrit à la main."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Classification avec une SVM\n",
    "\n",
    "## 4.1 SVM Linéaire\n",
    "\n",
    "Nous pouvons appliquer exactement la même recette algorithmique pour l'étude d'une SVM linéaire que pour celle d'une régression logistique régularisée. En effet, nous avons dans les deux cas un unique hyperparamètre, le coefficient de régularisation.\n",
    "\n",
    "La classification par SVM dans scikit-learn est implémentée par [svm.SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Définir une grille de valeurs pour le paramètre C\n",
    "param_grid = {'C': [0.05, 0.1, 0.5, 1., 5.]}\n",
    "\n",
    "# Definir un modèle de recherche sur grille pour une SVM\n",
    "#model_svc_lin = model_selection.GridSearchCV(svm.SVC(kernel='linear'),\n",
    "#                                         param_grid, \n",
    "#                                         scoring='f1', \n",
    "#                                         cv=kf_indices)\n",
    "\n",
    "# Implémentation dans le primal (à privilégier quand p < n)\n",
    "model_svc_lin = model_selection.GridSearchCV(svm.LinearSVC(dual=False),\n",
    "                                             param_grid, \n",
    "                                             scoring='f1', \n",
    "                                             cv=kf_indices)\n",
    "\n",
    "# Entraîner le modèle\n",
    "model_svc_lin.fit(X_train, y_train)\n",
    "\n",
    "# Meilleure valeur d'hyperparamètre\n",
    "print(\"C optimal :\", model_svc_lin.best_params_)\n",
    "\n",
    "# Performance du meilleur modèle\n",
    "print(\"F1 moyenne : %.3f\" % model_svc_lin.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 10 :__ Comment la performance de la SVM linéaire se compare-t-elle à celle de la régression logistique ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une SVM linéaire apprend une combinaison linéaire des variables décrivant les données. Nous pouvons comparer ce modèle à celui de la régression logistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le modèle optimal, entraîné sur l'ensemble des données d'entrainement,\n",
    "# est accessible dans model_svc_lin.best_estimator_\n",
    "fig = plt.figure(figsize(12, 6))\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "# Afficher les coefficients de la régression logistique\n",
    "plt.scatter(range(num_features), model_logreg.coef_,\n",
    "           label=\"Regression logistique\")\n",
    "\n",
    "# Afficher les coefficients de la SVM linéaire\n",
    "plt.scatter(range(num_features), model_svc_lin.best_estimator_.coef_,\n",
    "           label=\"SVM lineaire\")\n",
    "\n",
    "# Légende\n",
    "tmp = plt.legend(fontsize=14)\n",
    "\n",
    "# Axe des abcisses\n",
    "plt.xlabel('Variables', fontsize=14)\n",
    "feature_names = list(df.columns[1:])\n",
    "tmp = plt.xticks(range(num_features), feature_names, \n",
    "                 rotation=90, fontsize=14)\n",
    "\n",
    "# Axe des ordonnées\n",
    "tmp = plt.ylabel('Poids', fontsize=14)\n",
    "\n",
    "# Titre\n",
    "tmp = plt.title('Coefficients des modeles lineaires', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question  :__ Comment le modèle appris par la régression logistique et celui appris par la SVM linéaire se comparent-ils ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 SVM non linéaire\n",
    "\n",
    "L'utilisation d'un __noyau__ nous permet de créer des modèles non-linéaires, peut-être plus appropriés pour nos données. \n",
    "\n",
    "Cependant, il nous faut maintenant choisir aussi le noyau et ses hyperparamètres. En l'absence d'hypothèse forte sur le modèle, nous allons utiliser un noyau RBF gaussien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Définir une grille de valeurs pour le paramètre C de la SVM\n",
    "# et le paramètre gamma du noyau gaussien\n",
    "param_grid = {'C': [0.05, 0.1, 0.5, 1., 5.], \n",
    "             'gamma': [0.01, 0.1, 0.5]}\n",
    "\n",
    "# Definir un modèle de recherche sur grille pour une SVM\n",
    "model_svc_rbf = model_selection.GridSearchCV(svm.SVC(kernel='rbf'),\n",
    "                                         param_grid, \n",
    "                                         scoring='f1', \n",
    "                                         cv=kf_indices)\n",
    "\n",
    "# Entraîner le modèle\n",
    "model_svc_rbf.fit(X_train, y_train)\n",
    "\n",
    "# Meilleure valeur d'hyperparamètre\n",
    "print(\"Parametres optimaux : \", model_svc_rbf.best_params_)\n",
    "\n",
    "# Performance du meilleur modèle\n",
    "print(\"F1 moyenne : %.3f\" % model_svc_rbf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 11 :__ Comment la performance de la SVM à noyau gaussien se compare-t-elle à celle de la SVM linéaire ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question  12 :__ Quel(s) inconvénient(s) voyez-vous à l'utilisation d'un noyau gaussien plutôt que linéaire ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Arbres et forêts\n",
    "\n",
    "## 5.1 Arbre de décision\n",
    "\n",
    "Nous allons maintenant utiliser un type très différent d'algorithme nous permettant d'apprendre un modèle linéaire : les arbres de décision, implémentés dans scikit-learn par [tree.DecisionTreeClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 13 :__ Entre une SVM non-linéaire et un arbre de décision, lequel pensez-vous conduire à (1) un modèle interprétable (2) un modèle performant ? Lequel pensez-vous prendre plus de temps à entraîner ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons considérer comme hyperparamètre le nombre maximal de niveaux de l'arbre de décision, `max_depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Définir une grille de valeurs pour la profondeur de l'arbre de décision \n",
    "param_grid = {'max_depth': [2, 5, 10, 20, 30]}\n",
    "\n",
    "# Definir un modèle de recherche sur grille pour un arbre de décision\n",
    "model_tree = model_selection.GridSearchCV(tree.DecisionTreeClassifier(),\n",
    "                                        param_grid, \n",
    "                                         scoring='f1', \n",
    "                                         cv=kf_indices)\n",
    "\n",
    "# Entraîner le modèle\n",
    "model_tree.fit(X_train, y_train)\n",
    "\n",
    "# Meilleure valeur d'hyperparamètre\n",
    "print(\"Paramètres optimaux : \", model_tree.best_params_)\n",
    "\n",
    "# Performance du meilleur modèle\n",
    "print(\"F1 moyenne : %.3f\" % model_tree.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 14 :__ Que pensez-vous de cette performance ? Êtes-vous surpris ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Interprétation de l'arbre de décision \n",
    "\n",
    "### Visualisation\n",
    "\n",
    "Le code suivant, issu de la [documentation de scikit-learn](http://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html), nous permet de visualiser l'arbre de décision que nous venons d'apprendre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = model_tree.best_estimator_.tree_.node_count\n",
    "children_left = model_tree.best_estimator_.tree_.children_left\n",
    "children_right = model_tree.best_estimator_.tree_.children_right\n",
    "feature = model_tree.best_estimator_.tree_.feature\n",
    "threshold = model_tree.best_estimator_.tree_.threshold\n",
    "\n",
    "node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "while len(stack) > 0:\n",
    "    node_id, parent_depth = stack.pop()\n",
    "    node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "    # If we have a test node\n",
    "    if (children_left[node_id] != children_right[node_id]):\n",
    "        stack.append((children_left[node_id], parent_depth + 1))\n",
    "        stack.append((children_right[node_id], parent_depth + 1))\n",
    "    else:\n",
    "        is_leaves[node_id] = True\n",
    "\n",
    "print(\"L'arbre de décision a %s noeuds et \"\n",
    "      \"la structure suivante :\"\n",
    "      % n_nodes)\n",
    "for i in range(n_nodes):\n",
    "    if is_leaves[i]:\n",
    "        print(\"%snode=%s feuille.\" % (node_depth[i] * \"\\t\", i))\n",
    "    else:\n",
    "        print(\"%snode=%s noeud test: aller au noeud %s si %s <= %s sinon \"\n",
    "              \"aller au noeud %s.\"\n",
    "              % (node_depth[i] * \"\\t\",\n",
    "                 i,\n",
    "                 children_left[i],\n",
    "                 df.columns[1+feature[i]],\n",
    "                 threshold[i],\n",
    "                 children_right[i],\n",
    "                 ))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 15 :__ Cet arbre de décision vous parait-il si interprétable ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance des variables\n",
    "\n",
    "Pour interpréter l'arbre de décision, nous pouvons aussi regarder l'importance de chaque variable. Elle est d'autant plus grande que la variable permet de réduire l'erreur de classification de l'arbre.\n",
    "\n",
    "Nous remplaçons dans le code précédent `model_logreg.coefs_` (les coefficients du modèle linéaire) par `model_tree.best_estimator_.feature_importances_` (les importances de l'arbre de décision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize(12, 6))\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "# Afficher les valeurs absolues des \n",
    "# coefficients de la régression logistique\n",
    "plt.scatter(range(num_features), np.abs(model_logreg.coef_),\n",
    "           label=\"Regression logistique\")\n",
    "\n",
    "# Afficher les importances de l'arbre de décision,\n",
    "# multipliées par 10 pour être présentées sur la même échelle\n",
    "plt.scatter(range(num_features), 10*model_tree.best_estimator_.feature_importances_,\n",
    "           label=\"Arbre de decision\")\n",
    "\n",
    "# Légende\n",
    "tmp = plt.legend(fontsize=14)\n",
    "\n",
    "# Axe des abcisses\n",
    "plt.xlabel('Variables', fontsize=14)\n",
    "feature_names = list(df.columns[1:])\n",
    "tmp = plt.xticks(range(num_features), feature_names, \n",
    "                 rotation=90, fontsize=14)\n",
    "\n",
    "# Axe des ordonnées\n",
    "tmp = plt.ylabel('Importance/Poids', fontsize=14)\n",
    "\n",
    "# Titre\n",
    "tmp = plt.title('Importance des variables', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 16 :__ Quelles sont maintenant les variables les plus importantes ? Comment cela se compare-t-il aux modèles précédents ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Forêt aléatoire\n",
    "\n",
    "Peut-on améliorer les performances de l'arbre de décision en utilisant une méthode ensembliste ? Nous allons utiliser ici une forêt aléatoire,  implémentée dans scikit-learn comme [ensemble.RandomForestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons maintenant deux hyperparamètres, la profondeur maximale de chaque arbre, et le nombre d'arbres dans la forêt. \n",
    "\n",
    "Nous modifions encore une fois le code permettant de choisir ces hyperparamètres, pour considérer le nombre d'arbres `n_estimators` comme hyperparamètre, et `ensemble.RandomForestClassifier` comme classifieur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Définir une grille de valeurs pour les paramètres n_estimators\n",
    "# et max_depth\n",
    "param_grid = {'n_estimators': [10, 20, 50, 100, 300, 500],\n",
    "             'max_depth': [2, 5, 10, 20]}\n",
    "\n",
    "# Definir un modèle de recherche sur grille pour une forêt aléatoire\n",
    "model_forest = model_selection.GridSearchCV(ensemble.RandomForestClassifier(),\n",
    "                                             param_grid, \n",
    "                                             scoring='f1', \n",
    "                                             cv=kf_indices)\n",
    "\n",
    "# Entraîner le modèle\n",
    "model_forest.fit(X_train, y_train)\n",
    "\n",
    "# Meilleure valeur d'hyperparamètre\n",
    "print(\"Nombre d'arbres optimal :\", model_forest.best_params_)\n",
    "\n",
    "# Performance du meilleur modèle\n",
    "print(\"F1 moyenne : %.3f\" % model_forest.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 17 :__ Comment la performance de la forêt aléatoire se compare-t-elle aux performances précédentes ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons encore une fois regarder l'importance de chaque variable, pour le meilleur modèle de forêt aléatoire, `model_forest.best_estimator_` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize(12, 6))\n",
    "\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "# Afficher les valeurs absolues des \n",
    "# coefficients de la régression logistique\n",
    "plt.scatter(range(num_features), np.abs(model_logreg.coef_),\n",
    "           label=\"Regression logistique\")\n",
    "\n",
    "# Afficher les importances de l'arbre de décision,\n",
    "# multipliées par 10 pour être présentées sur la même échelle\n",
    "plt.scatter(range(num_features), 10*model_tree.best_estimator_.feature_importances_,\n",
    "           label=\"Arbre de decision\")\n",
    "\n",
    "# Afficher les importances de la forêt aléatoire\n",
    "plt.scatter(range(num_features), 10*model_forest.best_estimator_.feature_importances_,\n",
    "           label=\"Foret aleatoire\")\n",
    "\n",
    "# Légende\n",
    "tmp = plt.legend(fontsize=14)\n",
    "\n",
    "\n",
    "# Axe des abcisses\n",
    "plt.xlabel('Variables', fontsize=14)\n",
    "feature_names = list(df.columns[1:])\n",
    "tmp = plt.xticks(range(num_features), feature_names, \n",
    "                 rotation=90, fontsize=14)\n",
    "\n",
    "# Axe des ordonnées\n",
    "tmp = plt.ylabel('Importance', fontsize=14)\n",
    "\n",
    "# Titre\n",
    "tmp = plt.title('Importance des variables (foret aleatoire)', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 18 :__ Quelles sont maintenant les variables les plus importantes ? Comment cela se compare-t-il aux modèles précédents ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Modèle final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 19 :__ Lequel de ces modèles choisissez vous comme le plus performant pour classifier les champignons du jeu de test ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous allez maintenant évaluer le modèle que vous avez choisi sur le jeu de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = model_forest.best_estimator_ # TODO : insérez ici le nom du modèle que vous avez choisi.\n",
    "\n",
    "# Prédire sur le jeu de test\n",
    "y_pred = my_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour évaluer la performance, nous allons avoir besoin de metrics\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer la performance : score F1 sur le jeu de test\n",
    "print(\"Score F1 en test du modele choisi : %.3f\\n\" % metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "# Évaluer la performance : matrice de confusion \n",
    "print(\"Matrice de confusion du modele choisi :\\n\",  metrics.confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 20 :__ D'après la [documentation de metrics.confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix), la matrice de confusion contient les nombres suivants :\n",
    "``` \n",
    "    [[TN, FP]\n",
    "    [FN, TP]]\n",
    "```\n",
    "Combien de champignons avez-vous classifiés comme comestible alors qu'ils ne le sont pas ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
