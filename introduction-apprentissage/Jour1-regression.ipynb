{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à l'apprentissage automatique - Jour 1 - Régression\n",
    "\n",
    "Dans ce notebook, vous allez apprendre :\n",
    "* à vous servir d'un notebook Jupyter pour garder une trace de l'analyse de vos données ;\n",
    "* à étudier un problème de régression.\n",
    "    \n",
    "Ce notebook a été créé par [Chloé-Agathe Azencott](http://cazencott.info).\n",
    "\n",
    "Ce noteboook utilise les librairies suivantes :\n",
    "* python 3.7.7\n",
    "* numpy 1.18.4\n",
    "* matplotlib 3.2.1\n",
    "* scikit-learn 0.23.1\n",
    "\n",
    "Pour vérifier quelles versions de ces librairies vous utilisez, faites tourner la cellue ci-dessous en cliquant dessus puis en cliquant sur le bouton \"Play\" dans le menu au-dessus de cette fenêtre, ou en tapant Shift+Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "import numpy\n",
    "print(numpy.__version__)\n",
    "\n",
    "import matplotlib\n",
    "print(matplotlib.__version__)\n",
    "\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  Le notebook Jupyter\n",
    "\n",
    "Jupyter est une application web qui vous permet de créer et partager des documents appelés _notebooks_ (tels que ce notebook .ipynb) qui contient du code modifiable et exécutable, des visualisations, et du texte explicatoire qui peut être formaté avec une syntaxe markdown simple et contenir des équations.\n",
    "\n",
    "Quelques éléments concernant l'utilisation des notebooks Jupyter :\n",
    "* Chaque bloc éditable est contenu dans une cellule (_cell_). Un cellule peut contenit du texte brut (_raw text_), du code, ou du texte formatté avec la syntaxe markdown, comme cette cellule. Pour plus d'information sur la syntaxe markdown, suivez le [guide](http://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Working%20With%20Markdown%20Cells.html) !\n",
    "* Pour exécuter une cellule, il suffit de cliquer dessus et de taper Shift+Enter (ou d'utiliser le bouton Play dans la barre de menu).\n",
    "* Pour créer une nouvelle cellule vide en-dessous de celle que vous allez exécuter, utilisez Alt+Enter au lieu de Shift+Enter.\n",
    "* Le menu Insert vous permet aussi d'insérer de nouvelles cellules avant ou après la cellue courante.\n",
    "* Si le notebook ne répond plus, vous pouvez le redémarrer par le menu Kernel --> Restart.\n",
    "\n",
    "Quelques éléments concernant l'utilisation d'un notebook Jupyter avec Python :\n",
    "* Une cellule de code Python se comporte comme un shell Python interactif (et en particulier comme ipython, sur lequel est basé Jupyter). En particulier : \n",
    "  * Tabulation permet d'auto-compléter le mot-clé que vous avez commencé à taper\n",
    "  * Taper un point d'interrogation après le nom d'un objet charge l'aide interactive pour cette fonction.\n",
    "* Jupyter a des commandes Python spéciales (des raccourcis, en quelque sorte) qui s'appellent des _magics_. Par exemple, `%bash` permet d'exécuter du code bash (donc comme si vous étiez dans un terminal), `%paste` permet de coller un block de code précédemment copié (depuis le notebook ou une autre application) en conservant son formatage (et en particulier les indentations), et `%matplotlib inline` permet d'importer la librairie de visualisation de matplotlib et d'afficher les graphiques créés non pas dans une nouvelle fenêtre mais à l'intérieur du notebook. Vous trouverez une liste complète de _magics_ sur http://ipython.readthedocs.io/en/stable/interactive/magics.html \n",
    "\n",
    "\n",
    "### Ressources \n",
    "* Pour en savoir plus sur le shell python interactif : http://ipython.readthedocs.io/en/stable/interactive/tutorial.html\n",
    "* Pour en savoir plus sur Jupyter : https://jupyter.org/\n",
    "* Python et Python Scientifique : http://www.scipy-lectures.org/\n",
    "* Pour une introduction rapide aux différences entre shell python, shell python interactif, et notebook : https://www.youtube.com/watch?v=ULzWaZQa1Dc (en français)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Le problème du jour \n",
    "\n",
    "Nous allons travailler avec un jeu de données contenant des informations physico-chimiques sur un certain nombre de vins portugais (vinho verde), ainsi que les notes qui leur ont été attribuées par des gens qui les ont goûtés. Notre but est d'automatiser ce processus : nous voulons prédire directement la note des vins à partir de leurs caractéristiques physico-chimiques, afin d'assister les œnologues, améliorer la production de vin, et cibler les goûts de consomateurs de niche.\n",
    "\n",
    "Ce jeu de données est disponible sur l'archive UCI de jeux de données de machine learning, sur laquelle vous trouverez de nombreux jeux de données classiques : http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/. Pas besoin de le télécharger, il est déjà dans votre répertoire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Préparer les données\n",
    "\n",
    "## 3.1 Charger les librairies de science des données\n",
    "Nous allons commencer par importer les librairies nécessaires à notre analyse.\n",
    "\n",
    "La commande `%pylab inline` est une commande magique de Jupyter. Elle est équivalente à :\n",
    "\n",
    "```python \n",
    "  import numpy as np\n",
    "  import matplotlib.plot as plt```\n",
    "\n",
    "Numpy (Numerical Python) est la librairie Python de référence pour le calcul numérique, et en particulier pour la manipulation de vecteurs et matrices. Elle propose dans une certaine mesure des fonctionalités similaires à celles de Matlab.\n",
    "\n",
    "Matplotlib est une librairie de visualisation de données qui permet de tracer des graphiques.\n",
    "\n",
    "Le mot-clé `inline` précise que nous voulons que les figures apparaissent au sein du notebook et non pas dans une fenêtre séparée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour manipuler les données, nous allons utiliser la librairie pandas :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Charger les données\n",
    "\n",
    "Regardez le fichier `data/winequality-white.csv` (vous pouvez l'ouvrir avec un éditeur de texte, ou un logiciel tableur, ou en ligne de commande avec la commande `less`.) Il contient une première ligne (header) décrivant les colonnes, puis une ligne par vin. Nous allons le charger avec pandas :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('data/winequality-white.csv', # nom du fichier\n",
    "                       sep=\";\" # séparateur de colonnes\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant examiner ce fichier directement dans notre notebook, par exemple en en regardant les premières lignes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data` contient 12 colonnes. Les 11 premières (de \"fixed acidity\" à \"alcohol\") décrivent les caractéristiques physico-chimiques de nos vins, et la dernière (\"quality\") sa note."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre première tâche est de séparer ce tableau en la matrice de données X et le vecteur d'étiquettes y.\n",
    "\n",
    "__Question 1 :__ Quelles colonnes de `data` doivent former X ? Quelles colonnes doivent former y ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner toutes les lignes de `data` et toutes ses colonnes sauf la dernière :\n",
    "X = data.values[:, :-1]\n",
    "\n",
    "# Sélectionner toutes les lignes de `data` et sa dernière colonne uniquement :\n",
    "y = data.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les objets X et y que nous venons de créer sont des __arrays numpy__. Observons leurs dimensions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X est un objet de type ndarray, de forme 4898 x 11. Il représente une matrice de 4898 lignes et 11 colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(y))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y est un objet de type ndarray, de forme 4898. Il représente un vecteur de 4898 entrées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2 :__ Combien d'échantillons (examples) notre jeu de données contient-il ? Combien de variables ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Séparer les données en un jeu d'entraînement et un jeu de test\n",
    "\n",
    "Pour pouvoir évaluer un modèle d'apprentissage de façon non-biaisée, nous avons besoin de créer un jeu de test contenant des données sur lequel le modèle n'a pas été entraîné. Ce jeu de test correspond à des données « nouvelles ».\n",
    "\n",
    "Nous pourrions faire cette séparation « à la main », mais c'est une des nombreuses fonctionalités proposées par la librairie d'apprentissage statistique scikit-learn. [La documentation de cette librairie](http://scikit-learn.org/stable/documentation.html) vous sera très utile au cours de cette séance pratique et, de manière plus générale, pour comprendre les algorithmes d'apprentissage automatique.\n",
    "\n",
    "Plus précisément, nous allons utiliser la fonction [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) du module `model_selection` de scikit-learn :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    model_selection.train_test_split(X, y,\n",
    "                                    test_size=0.3 # 30% des données dans le jeu de test\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 3 :__ Combien d'échantillons le jeu d'entraînement (X_train, y_train) contient-il ? Et le jeu de test (X_test, y_test) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Écrire ici le code permettant de répondre à la question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Régression linéaire \n",
    "\n",
    "Nous sommes maintenant prêts à entraîner notre premier modèle d'apprentissage statistique ! Il va s'agir d'un modèle de régression linéaire.\n",
    "\n",
    "L'algorithme permettant d'entraîner une régression linéaire se trouve dans le module [linear models](http://scikit-learn.org/stable/modules/linear_model.html#linear-model) de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Entraîner une régression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle de régression linéaire \n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "# Entraîner ce modèle sur (X_train, y_train)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Évaluer le modèle \n",
    "\n",
    "Le module [metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) de scikit-learn nous permet d'évaluer facilement un modèle sur un jeu de données. Nous avons ici un problème de __régression__. Une des métriques appropriées est l'erreur quadratique moyenne (MSE). Pour d'autres métriques, voir http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter.\n",
    "\n",
    "Rappelez-vous, nous évaluons le modèle sur le jeu de test !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Prédire les étiquettes du jeu de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculer la MSE du modèle sur le jeu de test\n",
    "print(\"MSE (test) : %0.3f\" % metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 4 :__ Pensez-vous que ce score est plutôt bon ? Plutôt mauvais ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons aussi comparer visuellement les étiquettes prédites aux étiquettes réelles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une figure de taille 6 x 6\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Créer un nuage de points (\"scatterplot\") présentant, pour chaque échantillon du jeu de test,\n",
    "# son étiquette prédite (en ordonnée) versus son étiquette réelle (en abcisse)\n",
    "plt.scatter(y_test, y_pred)\n",
    "\n",
    "# Étiqueter les axes\n",
    "tmp = plt.xlabel(\"Etiquette reelle\", fontsize=14)\n",
    "tmp = plt.ylabel(\"Etiquette predite\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 5 :__ Pensez-vous que les prédictions sont plutôt bonnes ? Plutôt mauvaises ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 6 :__ Que pensez-vous du choix d'aborder ce problème comme un problème de régression ? Quelle(s) alternative(s) pouvez-vous suggérer ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Visualiser le modèle \n",
    "\n",
    "### Afficher les coefficients du modèle de régression linéaire\n",
    "\n",
    "Un des avantages des modèles linéaires est leur __interprétabilité__ : nous pouvons visualiser les coefficients de régression affectés à chacune des variables, et en tirer des conclusions sur leur importance relative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le nombre de variable\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "# Afficher pour chaque variable son coefficient dans le modèle\n",
    "plt.scatter(range(num_features), # en abcisse : indices des variables\n",
    "            model.coef_ # en ordonnées : leur poids dans le modèle\n",
    "           )\n",
    "\n",
    "# Étiqueter les graduations de l'axe des abcsisses\n",
    "tmp = plt.xticks(range(num_features), # une marque par variable\n",
    "                 list(data.columns),  # afficher le nom de la variable\n",
    "                 rotation=90, # tourner les étiquettes de 90 degrés\n",
    "                 fontsize=14)\n",
    "\n",
    "# Étiqueter les axes\n",
    "tmp = plt.xlabel('Variable', fontsize=14)\n",
    "tmp = plt.ylabel('Coefficient', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 7 :__ D'après ce graphique, quelle(s) variable(s) semble(nt) avoir le plus d'importance dans le modèle ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Échelles des variables \n",
    "\n",
    "La variable `density` a un coefficient beaucoup plus important (en valeur absolue) que les autres. Mais est-elle pour autant la plus importante ? Il nous faut prendre en compte _l'échelle_ des valeurs prises par les différentes variables.\n",
    "\n",
    "Nous avons la chance ici d'avoir un petit nombre de variables dans nos données. Nous pouvons donc facilement les examiner grâce à des histogrammes. Nous allons disposer ces 11 histogrammes sur une grille de taille 3 lignes x 4 colonnes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer une figure de taille 16x12\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "# pour chaque variable\n",
    "for feat_idx in range(X_train.shape[1]):\n",
    "    # créer une sous-figure à la position (feat_idx+1) d'une grille 3x4 \n",
    "    ax = fig.add_subplot(3, 4, (feat_idx+1))\n",
    "    # afficher l'histogramme de la variable feat_idx\n",
    "    h = ax.hist(X_train[:, feat_idx], # la colonne d'indice feat_idx de notre jeu d'entraînement\n",
    "                bins=50, # le nombre de barres à créer\n",
    "                color='steelblue', # la couleur de la barre\n",
    "                edgecolor='none')\n",
    "    # utiliser le nom de la variable comme titre de l'histogramme\n",
    "    ax.set_title(data.columns[feat_idx], # le texte\n",
    "                 fontsize=14 # la taille de police à utiliser\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque barre d'un histogramme correspond à une petite fourchette de valeur (équivalente à la largeur de sa base). Sa hauteur donne le nombre d'échantillons dans `X_train` pour lesquels la variable considérée prend une valeur dans cette fourchette.\n",
    "\n",
    "__Question 8 :__ Comparez les valeurs prises par la variable `density` avec celles prises par la variable `free sulphur dioxide`. Pensez-vous toujours que `density` est la variable la plus importante du modèle ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Standardisation des variables\n",
    "\n",
    "## 5.1 Centrer-réduire les données\n",
    "\n",
    "Nous venons d'observer que le fait d'avoir des variables qui suivent des étendues de valeurs différentes limite l'interprétabilité du modèle.\n",
    "\n",
    "Cela pose en fait aussi problème en ce qui concerne la performance des modèles entraînés. C'est pour cela qu'il est préférable de __standardiser__ ses données, ou encore de les __centrer-réduire__ (\"standardiser\" est un anglicisme), pour faire en sorte que toutes les variables aient une moyenne de 0 (elles sont centrées) et un écart-type de 1 (c'est la réduction). Cela permet de rendre toutes les variables comparables entre elles. \n",
    "\n",
    "C'est encore une fois quelque chose que nous pouvons faire avec scikit-learn, grâce au module [preprocessing.StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Créer un \"standardiseur\" et le calibrer sur les données d'entraînement\n",
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "# Appliquer la standardisation aux données d'entraînement\n",
    "X_train_std = std_scale.transform(X_train)\n",
    "\n",
    "# Appliquer la standardisation aux données de test\n",
    "X_test_std = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 9 :__ Pourquoi a-t-on calibré `std_scale` (c'est-à-dire calculé les moyennes et écart-types de chaque variable) sur les données d'entraînement uniquement ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant visualiser les variables centrées-réduites (en remplaçant `X_train` par `X_train_std` dans le code précédent) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer une figure de taille 16x12\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "# pour chaque variable\n",
    "for feat_idx in range(X_train_std.shape[1]):\n",
    "    # créer une sous-figure à la position (feat_idx+1) d'une grille 3x4 \n",
    "    ax = fig.add_subplot(3, 4, (feat_idx+1))\n",
    "    # afficher l'histogramme de la variable feat_idx\n",
    "    h = ax.hist(X_train_std[:, feat_idx], # la colonne d'indice feat_idx de notre jeu d'entraînement\n",
    "                bins=50, # le nombre de barres à créer\n",
    "                color='steelblue', # la couleur de la barre\n",
    "                edgecolor='none')\n",
    "    # utiliser le nom de la variable comme titre de l'histogramme\n",
    "    ax.set_title(data.columns[feat_idx], # le texte\n",
    "                 fontsize=14 # la taille de police à utiliser                \n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 10 :__ Comparer les étendues de valeurs de `density` et de `free sulfur dioxide` centrées-réduites, entre elles et avec leurs équivalents non centrées-réduites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Régression linéaire sur les données centrées-réduites \n",
    "\n",
    "Nous allons maintenant recommencer notre analyse de la régression linéaire, sur les données centrées-réduites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle de régression linéaire \n",
    "model_cr = linear_model.LinearRegression()\n",
    "\n",
    "# Entraîner ce modèle sur (X_train_std, y_train)\n",
    "model_cr.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Prédire les étiquettes du jeu de test centré-réduit\n",
    "y_pred_cr = model_cr.predict(X_test_std)\n",
    "\n",
    "# Calculer la MSE du modèle sur le jeu de test centré-réduit\n",
    "print(\"MSE (test, centré-réduit) : %0.3f\" % metrics.mean_squared_error(y_test, y_pred_cr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 11 :__ Comparer la MSE obtenue sur les données centrées-réduites à celle obtenue sur les données initiales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En fait, centrer-réduire les données ne change pas la régression linéaire, au sens où le modèle appris fait exactement les mêmes prédictions. Nous pouvons le vérifier sur nos données, en calculant la norme de la différence entre les prédictions faites sur les données initiales (`y_pred`) et celles faites sur les données centrées-réduites (`y_pred_cr`). (Cette norme est la somme des carrés des différences entre les prédictions.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%.3e\" % np.linalg.norm(y_pred - y_pred_cr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 12 :__ Pourquoi la régression linéaire ne change-t-elle pas si les données sont centrées-réduites ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que les variables ont toutes été ramenées à la même échelle, nous pouvons comparer de nouveaux les poids du modèle de régression :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer le nombre de variables\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "# Afficher pour chaque variable son coefficient dans le modèle\n",
    "plt.scatter(range(num_features), # en abcisse : indices des variables\n",
    "            model_cr.coef_ # en ordonnées : leur poids dans le modèle\n",
    "           )\n",
    "\n",
    "# Étiqueter les graduations de l'axe des abcsisses\n",
    "tmp = plt.xticks(range(num_features), # une marque par variable\n",
    "                 list(data.columns),  # afficher le nom de la variable\n",
    "                 rotation=90, # tourner les étiquettes de 90 degrés\n",
    "                 fontsize=14)\n",
    "\n",
    "# Étiqueter les axes\n",
    "tmp = plt.xlabel('Variable', fontsize=14)\n",
    "tmp = plt.ylabel('Coefficient', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 13 :__ D'après ce graphique, quelles sont maintenant les variables qui semblent avoir le plus d'importance dans le modèle ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Sélection de modèle\n",
    "\n",
    "## 6.1 Mettre en place une validation croisée\n",
    "\n",
    "Nous allons maintenant utiliser d'autres algorithmes pour créer de nouveaux modèles. Il va nous falloir choisir entre ces différents modèles : c'est ce que l'on appelle la __sélection de modèle.__ \n",
    "Attention ! Nous ne pouvons pas utiliser le jeu de test pour cette étape de sélection, car sinon nous pourrions biaiser le modèle et surapprendre.\n",
    "Pour comparer nos modèles __sur le jeu d'entraînement__, nous allons utiliser une __validation croisée__, encore une fois grâce au module [http://scikit-learn.org/stable/model_selection.html#model-selection](model-selection) de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "# Créer un objet KFold qui permettra de cross-valider en 5 folds\n",
    "kf = model_selection.KFold(n_splits=5,  # 5 folds\n",
    "                           shuffle=True # mélanger les échantillons avant de créer les folds\n",
    "                          )\n",
    "\n",
    "# Utiliser kf pour partager le jeu d'entraînement en 5 folds. \n",
    "# kf.split retourne un iterateur (consommé après une boucle).\n",
    "# Pour pouvoir se servir plusieurs fois des mêmes folds, nous transformons cet itérateur en liste d'indices :\n",
    "kf_indices = list(kf.split(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combien d'éléments cette liste contient-elle ?\n",
    "print(len(kf_indices))\n",
    "# Quel est le type du premier élément ?\n",
    "print(type(kf_indices[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf_indices est donc une liste de 5 tuples.\n",
    "# Quel est le type des éléments formant un de ces tuples ?\n",
    "print(type(kf_indices[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf_indices est une liste de 5 tuples de deux arrays\n",
    "# Quelles sont les tailles de ces arrays (pour le premier tuple) ?\n",
    "print(kf_indices[0][0].shape)\n",
    "print(kf_indices[0][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kf_indices` contient 5 paires de deux vecteurs d'indices. Chacune de ces paires correspond à un fold. Le premier vecteur donne les indices des échantillons formant la partie entraînement de ce fold. Le deuxième donne les indices des échantillons formant la partie test de ce fold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 14 :__ Combien de fois chaque échantillon apparaît-il dans la partie entraînement d'un fold ? Dans la partie test ? (Il n'est pas nécessaire d'écrire de code pour répondre.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Validation croisée pour la régression linéaire \n",
    "\n",
    "Nous devons maintenant reprendre notre travail sur la régression linéaire. Heureusement, scikit-learn nous permet grâce à [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) d'évaluer la performance en validation croisée d'un modèle de régression linéaire sans que nous ne devions nous-même entraîner et évaluer le modèle sur chaque fold, puis combiner les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un modèle de régression linéaire \n",
    "model_linreg = linear_model.LinearRegression()\n",
    "\n",
    "# L'évaluer en validation croisée\n",
    "nmse_linreg = model_selection.cross_val_score(model_linreg, # modèle à entraîner\n",
    "                                      X_train_std, y=y_train, # jeu d'entrainement\n",
    "                                      scoring='neg_mean_squared_error', # score à utiliser\n",
    "                                      cv=kf_indices # validation croisée à utiliser\n",
    "                                      )\n",
    "# Afficher nmse_linreg\n",
    "print([\"%.3f\" % value for value in nmse_linreg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nmse_linreg` contient l'opposé de l'erreur quadratique moyenne sur chacun des 5 folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 15 :__ Pourquoi donc _l'opposé_ de l'erreur quadratique moyenne ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant calculer la moyenne sur nos 5 folds de validation croisée de l'erreur quadratique moyenne d'une régression linéaire, et l'écart-type de cette valeur. L'écart-type nous indique à quel point les 5 valeurs fluctuent autour de leur moyenne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE de la régression linéaire : %.3f +/- %.3f\" % (np.mean(-nmse_linreg), # moyenne\n",
    "                                                         np.std(-nmse_linreg) # écart-type\n",
    "                                                        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 16 :__ Comparez la MSE obtenue précédemment sur le jeu de test à celle obtenue en validation croisée. Pensez-vous que la régression linéaire surapprend ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Validation croisée pour la régression ridge\n",
    "\n",
    "Nous allons maintenant évaluer un modèle de régression linéaire régularisée ridge -- voir la section [ridge regression]( http://scikit-learn.org/stable/modules/linear_model.html#ridge-regression) de scikit-learn. \n",
    "\n",
    "### Évaluation de plusieurs modèles\n",
    "\n",
    "La régression ridge a un __hyperparamètre__, appelé $\\alpha$ dans scikit-learn, qui contrôle la quantité de régularisation utilisée. Nous allons tester plusieurs valeurs pour $\\alpha$, et créer pour cela 50 valeurs équiréparties (en échelle logarithmique) entre $10^{-1}$ and $10^4$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 valeurs de alpha :\n",
    "alphas = np.logspace(-1, 4, 50)\n",
    "\n",
    "nmse_per_alpha = [] # pour enregistrer les valeurs de -MSE values pour chacune des 50 valeurs de alpha\n",
    "weights_per_alpha = [] # pour enregistrer les coefficients associés à chaque variable,  \n",
    "                       # pour les 50 valeurs de alpha\n",
    "for alf in alphas:\n",
    "    # Créer un modèle de régression ridge\n",
    "    model_ridge = linear_model.Ridge(alpha=alf)\n",
    "    \n",
    "    # Calculer la performance en validation croisée du modèle\n",
    "    nmse = model_selection.cross_val_score(model_ridge, \n",
    "                                           X_train_std, y=y_train, \n",
    "                                           scoring='neg_mean_squared_error', \n",
    "                                           cv=kf_indices)\n",
    "    nmse_per_alpha.append(nmse)\n",
    "    \n",
    "    # Entrainer le modèle sur le jeu d'entrainement total \n",
    "    model_ridge.fit(X_train_std, y_train)\n",
    "    \n",
    "    # Enregistrer les coefficients de régression \n",
    "    weights_per_alpha.append(model_ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évolution de l'erreur du modèle en fonction de alpha\n",
    "\n",
    "Nous pouvons maintenant regarder comment l'erreur du modèle de régression ridge évolue en fonction de $\\alpha$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas, # abcisse\n",
    "         np.mean(-np.array(nmse_per_alpha), axis=1) # ordonnée : MSE moyenne\n",
    "        )\n",
    "plt.xscale('log') # utiliser une échelle logarithmique en abcisse\n",
    "\n",
    "# Étiqueter les axes\n",
    "tmp = plt.xlabel('Valeur de alpha', fontsize=14)\n",
    "tmp = plt.ylabel('MSE moyenne', fontsize=14)\n",
    "\n",
    "# Titre\n",
    "tmp = plt.title(\"Regression ridge\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour avoir encore plus d'information, nous pouvons aussi afficher des barres d'erreur sur chacun des points.\n",
    "\n",
    "Il est classique d'utiliser $2 \\sigma / \\sqrt{n}$ comme hauteur de barre d'erreur, ou $\\sigma$ est l'écart-type et $n$ le nombre de mesures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(alphas, # abcisse\n",
    "             np.mean(-np.array(nmse_per_alpha), axis=1), # ordonnée : MSE moyenne\n",
    "             yerr=np.std(-np.array(nmse_per_alpha), axis=1)/np.sqrt(5) # barre d'erreur verticale\n",
    "            )\n",
    "plt.xscale('log') # utiliser une échelle logarithmique en abcisse\n",
    "\n",
    "# Étiqueter les axes\n",
    "tmp = plt.xlabel('Valeur de alpha', fontsize=14)\n",
    "tmp = plt.ylabel('MSE moyenne', fontsize=14)\n",
    "\n",
    "# Titre\n",
    "tmp = plt.title(\"Regression ridge\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 15 :__ Comment l'erreur du modèle (en validation croisée) évolue-t-elle en fonction de la quantité de régularisation ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 16 :__ Ces résultats pour la régression ridge vous semblent-ils cohérents avec la MSE en validation croisée obtenue pour la régression linéaire non-régularisée ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évolution des coefficients de régression en fonction de alpha\n",
    "\n",
    "Nous pouvons aussi regarder l'évolution, pour chaque variable, du coefficient lui correspondant dans le modèle final, en fonction de $\\alpha$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une figure\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "\n",
    "lines = plt.plot(alphas, # abcisse = valeurs de alpha\n",
    "                 weights_per_alpha # ordonnée = valeurs des coefficients de régression\n",
    "                ) \n",
    "plt.xscale('log') # échelle logarithmique en abcisse\n",
    "\n",
    "# Afficher la légende\n",
    "tmp = plt.legend(lines, # récupérer l'identifiant \n",
    "                 list(data.columns), # nom de chaque variable\n",
    "                 frameon=False, # pas de cadre autour de la légende\n",
    "                 loc=(1, 0),  # placer la légende à droite de l'image\n",
    "                 fontsize=14)\n",
    "\n",
    "tmp = plt.xlabel('alpha', fontsize=14)\n",
    "tmp = plt.ylabel('Coefficient', fontsize=14)\n",
    "\n",
    "tmp = plt.title('Regression ridge', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 17 :__ Comment les coefficients du modèle évoluent-t-ils en fonction de la quantité de régularisation ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 18 :__ Ces coefficients pour la régression ridge vous semblent-ils cohérents avec ceux obtenus pour la régression linéaire non-régularisée ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle optimal de régression ridge\n",
    "\n",
    "Nous pouvons maintenant sélectionner, parmi nos 50 modèles de régression ridge, celui qui a la plus petite erreur en validation croisée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver l'index de la valeur optimale de alpha\n",
    "best_ridge_idx = np.argmin(-np.mean(nmse_per_alpha))\n",
    "\n",
    "# Valeur de alpha optimale\n",
    "print(\"Valeur de alpha optimale (regression ridge) : %.3e\" % alphas[best_ridge_idx])\n",
    "\n",
    "# MSE correspondante\n",
    "print(\"Erreur (validation croisée) du modele de regression ridge optimal : %.3f +/- %.3f\" % \\\n",
    "     (np.mean(-np.array(nmse_per_alpha)[best_ridge_idx]), # valeur moyenne\n",
    "      np.std(-np.array(nmse_per_alpha)[best_ridge_idx]) # écart-type\n",
    "     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Validation croisée pour le lasso\n",
    "\n",
    "Nous allons maintenant évaluer un modèle de régression linéaire régularisée lasso -- voir la section [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) de scikit-learn. \n",
    "\n",
    "La régression lasso a aussi un __hyperparamètre__, appelé $\\alpha$ dans scikit-learn, qui contrôle la quantité de régularisation utilisée. Nous allons reproduire l'analyse effectuée pour la régression ridge. \n",
    "\n",
    "Remarquez que nous utilisons ici une grille de valeurs de $\\alpha$ différente de celle de la régression ridge.\n",
    "\n",
    "### Évaluation de plusieurs modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 valeurs de alpha :\n",
    "alphas = np.logspace(-3, 1, 50)\n",
    "\n",
    "nmse_per_alpha_lasso = [] # pour enregistrer les valeurs de -MSE values pour chacune des 50 valeurs de alpha\n",
    "weights_per_alpha_lasso = [] # pour enregistrer les coefficients associés à chaque variable,  \n",
    "                       # pour les 50 valeurs de alpha\n",
    "for alf in alphas:\n",
    "    # Créer un modèle de régression ridge\n",
    "    model_lasso = linear_model.Lasso(alpha=alf)\n",
    "    \n",
    "    # Calculer la performance en validation croisée du modèle\n",
    "    nmse = model_selection.cross_val_score(model_lasso, \n",
    "                                           X_train_std, y=y_train, \n",
    "                                           scoring='neg_mean_squared_error', \n",
    "                                           cv=kf_indices)\n",
    "    nmse_per_alpha_lasso.append(nmse)\n",
    "    \n",
    "    # Entrainer le modèle sur le jeu d'entrainement total \n",
    "    model_lasso.fit(X_train_std, y_train)\n",
    "    \n",
    "    # Enregistrer les coefficients de régression \n",
    "    weights_per_alpha_lasso.append(model_lasso.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évolution de l'erreur du modèle en fonction de alpha\n",
    "\n",
    "Nous pouvons maintenant regarder comment l'erreur du modèle de lasso évolue en fonction de $\\alpha$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(alphas, # abcisse\n",
    "             np.mean(-np.array(nmse_per_alpha_lasso), axis=1), # ordonnée : MSE moyenne\n",
    "             yerr=np.std(-np.array(nmse_per_alpha_lasso), axis=1)/np.sqrt(5) # barre d'erreur verticale\n",
    "            )\n",
    "plt.xscale('log') # utiliser une échelle logarithmique en abcisse\n",
    "\n",
    "# Étiqueter les axes\n",
    "tmp = plt.xlabel('Valeur de alpha', fontsize=14)\n",
    "tmp = plt.ylabel('MSE moyenne', fontsize=14)\n",
    "\n",
    "# Titre\n",
    "tmp = plt.title(\"Lasso\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 19 :__ Comment l'erreur du modèle (en validation croisée) évolue-t-elle en fonction de la quantité de régularisation ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 20 :__ Ces résultats pour le lasso vous semblent-ils cohérents avec la MSE en validation croisée obtenue pour la régression linéaire non-régularisée ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évolution des coefficients de régression en fonction de alpha\n",
    "\n",
    "Nous pouvons aussi regarder l'évolution, pour chaque variable, du coefficient lui correspondant dans le modèle final, en fonction de $\\alpha$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une figure\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "\n",
    "lines = plt.plot(alphas, # abcisse = valeurs de alpha\n",
    "                 weights_per_alpha_lasso # ordonnée = valeurs des coefficients de régression\n",
    "                ) \n",
    "plt.xscale('log') # échelle logarithmique en abcisse\n",
    "\n",
    "# Afficher la légende\n",
    "tmp = plt.legend(lines, # récupérer l'identifiant \n",
    "                 list(data.columns), # nom de chaque variable\n",
    "                 frameon=False, # pas de cadre autour de la légende\n",
    "                 loc=(1, 0),  # placer la légende à droite de l'image\n",
    "                 fontsize=14)\n",
    "\n",
    "tmp = plt.xlabel('alpha', fontsize=14)\n",
    "tmp = plt.ylabel('Coefficient', fontsize=14)\n",
    "\n",
    "tmp = plt.title('Lasso', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 21 :__ Comment les coefficients du modèle évoluent-t-ils en fonction de la quantité de régularisation ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 22 :__ Ces coefficients pour le lasso vous semblent-ils cohérents avec ceux obtenus pour la régression linéaire non-régularisée ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 23 :__ Si vous deviez choisir uniquement deux variables pour construire un modèle, lesquelles utiliseriez-vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Réponse :__ _Écrire ici votre réponse._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle optimal de lasso\n",
    "\n",
    "Nous pouvons maintenant sélectionner, parmi nos 50 modèles de lasso, celui qui a la plus petite erreur en validation croisée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver l'index de la valeur optimale de alpha\n",
    "best_lasso_idx = np.argmin(-np.mean(nmse_per_alpha_lasso))\n",
    "\n",
    "# Valeur de alpha optimale\n",
    "print(\"Valeur de alpha optimale (régression ridge) : %.3e\" % alphas[best_lasso_idx])\n",
    "\n",
    "# MSE correspondante\n",
    "print(\"Erreur (validation croisée) du modèle de régression ridge optimal : %.3f +/- %.3f\" % \\\n",
    "     (np.mean(-np.array(nmse_per_alpha_lasso)[best_lasso_idx]), # valeur moyenne\n",
    "      np.std(-np.array(nmse_per_alpha_lasso)[best_lasso_idx]) # écart-type\n",
    "     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remarque :__ Ce problème est un cas de figure assez simple, avec très peu de variables. C'est pour cela que la régularisation ne semble pas apporter grand chose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Un cas p >> n\n",
    "\n",
    "Pour illustrer l'intérêt de la régularisation sur un exemple en grande dimension, nous utilisons ici des données d'expressions de gène mesurées sur des tumeurs de l'endomètre et de l'ovaire. Les données proviennent initialement de http://gemler.fzv.uni-mb.si/index.php mais ont été transformées pour faciliter le travail.\n",
    "\n",
    "Les données contiennent l'expression de 3.000 gènes, mesurées pour 61 tumeurs de l'endomètre et 123 de l'utérus. L'expression d'un gène est une mesure de la quantité d'ARN messager produite par transcription à partir de ce gène ; l'ARN messager sera ensuite traduit en une protéine, qui assurera une fonction dans l'organisme. La quantité d'ARN messager est indicavtive (la biologie n'est pas si simple) de la quantité de protéine que l'on peut espérer obtenir, mais est beaucoup plus facile à mesurer.  \n",
    "\n",
    "Il s'agit ici de classifier les échantillons entre ceux issus d'une tumeur de l'utérus et ceux issu d'une tumeur de l'endomètre, et donc d'un problème de _classification_ et non pas de régression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "X = np.loadtxt('data/small_Endometrium_Uterus.csv',  delimiter=',', skiprows=1, usecols=range(1, 3001))\n",
    "y = np.loadtxt('data/small_Endometrium_Uterus.csv', delimiter=',', \n",
    "               skiprows=1, usecols=[3001], dtype='bytes').astype('str')\n",
    "# Convert 'Endometrium' to 0 and 'Uterus' to 1\\n\n",
    "y = np.where(y=='Endometrium', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    model_selection.train_test_split(X, y,\n",
    "                                    test_size=0.3 # 30% des données dans le jeu de test\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Créer un \"standardiseur\" et le calibrer sur les données d'entraînement\n",
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "# Appliquer la standardisation aux données d'entraînement\n",
    "X_train_std = std_scale.transform(X_train)\n",
    "\n",
    "# Appliquer la standardisation aux données de test\n",
    "X_test_std = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "# Créer un objet KFold qui permettra de cross-valider en 5 folds\n",
    "kf = model_selection.KFold(n_splits=5,  # 5 folds\n",
    "                           shuffle=True # mélanger les échantillons avant de créer les folds\n",
    "                          )\n",
    "\n",
    "# Utiliser kf pour partager le jeu d'entraînement en 5 folds. \n",
    "# kf.split retourne un iterateur (consommé après une boucle).\n",
    "# Pour pouvoir se servir plusieurs fois des mêmes folds, nous transformons cet itérateur en liste d'indices :\n",
    "kf_indices = list(kf.split(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Créer un modèle de régression logistique non régularisée\n",
    "model_logreg = linear_model.LogisticRegression(C=1e10)\n",
    "\n",
    "# L'évaluer en validation croisée\n",
    "acc_logreg = model_selection.cross_val_score(model_logreg, # modèle à entraîner\n",
    "                                      X_train_std, y=y_train, # jeu d'entrainement\n",
    "                                      scoring='accuracy', # score à utiliser\n",
    "                                      cv=kf_indices # validation croisée à utiliser\n",
    "                                      )\n",
    "# Afficher acc_loreg\n",
    "print([\"%.3f\" % value for value in acc_logreg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 valeurs de alpha :\n",
    "alphas = np.logspace(-6, 8, 50)\n",
    "\n",
    "acc_per_alpha_l2 = [] # pour enregistrer les valeurs d'accuracy pour chacune des 50 valeurs de alpha\n",
    "\n",
    "for alf in alphas:\n",
    "    # Créer un modèle de régression logistique régularisée l1\n",
    "    model_l2 = linear_model.LogisticRegression(C=1./alf, penalty='l2')\n",
    "    \n",
    "    # Calculer la performance en validation croisée du modèle\n",
    "    acc = model_selection.cross_val_score(model_l2, \n",
    "                                           X_train_std, y=y_train, \n",
    "                                           scoring='accuracy', \n",
    "                                           cv=kf_indices)\n",
    "    acc_per_alpha_l2.append(acc)\n",
    "    \n",
    "    # Entrainer le modèle sur le jeu d'entrainement total \n",
    "    model_l2.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(alphas, # abcisse\n",
    "             np.mean(np.array(acc_per_alpha_l2), axis=1), # ordonnée : MSE moyenne\n",
    "             yerr=np.std(np.array(acc_per_alpha_l2), axis=1)/np.sqrt(5) # barre d'erreur verticale\n",
    "            )\n",
    "plt.xscale('log') # utiliser une échelle logarithmique en abcisse\n",
    "\n",
    "plt.plot(alphas, [np.mean(acc_logreg) for a in alphas])\n",
    "\n",
    "# Étiqueter les axes\n",
    "tmp = plt.xlabel('Valeur de alpha', fontsize=14)\n",
    "tmp = plt.ylabel('Accuracy moyenne', fontsize=14)\n",
    "\n",
    "# Titre\n",
    "tmp = plt.title(\"Regression logistique l2\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 valeurs de alpha :\n",
    "alphas = np.logspace(-10, 2, 50)\n",
    "\n",
    "acc_per_alpha_lasso = [] # pour enregistrer les valeurs d'accuracy pour chacune des 50 valeurs de alpha\n",
    "\n",
    "for alf in alphas:\n",
    "    # Créer un modèle de régression logistique régularisée l1\n",
    "    model_lasso = linear_model.LogisticRegression(C=1./alf, penalty='l1', solver='liblinear')\n",
    "    \n",
    "    # Calculer la performance en validation croisée du modèle\n",
    "    acc = model_selection.cross_val_score(model_lasso, \n",
    "                                           X_train_std, y=y_train, \n",
    "                                           scoring='accuracy', \n",
    "                                           cv=kf_indices)\n",
    "    acc_per_alpha_lasso.append(acc)\n",
    "    \n",
    "    # Entrainer le modèle sur le jeu d'entrainement total \n",
    "    model_lasso.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(alphas, # abcisse\n",
    "             np.mean(np.array(acc_per_alpha_lasso), axis=1), # ordonnée : MSE moyenne\n",
    "             yerr=np.std(np.array(acc_per_alpha_lasso), axis=1)/np.sqrt(5) # barre d'erreur verticale\n",
    "            )\n",
    "plt.xscale('log') # utiliser une échelle logarithmique en abcisse\n",
    "\n",
    "plt.plot(alphas, [np.mean(acc_logreg) for a in alphas])\n",
    "\n",
    "# Étiqueter les axes\n",
    "tmp = plt.xlabel('Valeur de alpha', fontsize=14)\n",
    "tmp = plt.ylabel('Accuracy moyenne', fontsize=14)\n",
    "\n",
    "# Titre\n",
    "tmp = plt.title(\"Regression logistique l1\", fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
