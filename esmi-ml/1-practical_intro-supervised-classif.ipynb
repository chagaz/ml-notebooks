{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical session introducing supervised classification with SciKit-Learn\n",
    "\n",
    "In this notebook, you will:\n",
    "* learn to use a \"Jupyter notebook\" to perform your data analysis and machine-learning work *and keep track of every step*;\n",
    "* get familiarized with scikit-learn library;\n",
    "* develop a first classification algorithm.\n",
    "\n",
    "This noteboook uses the following libraries:\n",
    "* python3 \n",
    "* numpy\n",
    "* matplotlib \n",
    "* scikit-learn \n",
    "\n",
    "In order to verify if these library are properly installed on your computer, and check which versions, run the cell below by clicking on it and then on the \"Play\" button above this window (or use the Shift+Enter shortcut)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10 | packaged by conda-forge | (default, Sep 13 2021, 21:12:34) [MSC v.1916 64 bit (AMD64)]\n",
      "1.20.3\n",
      "3.4.3\n",
      "0.24.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "\n",
    "import numpy\n",
    "print(numpy.__version__)\n",
    "\n",
    "import matplotlib\n",
    "print(matplotlib.__version__)\n",
    "\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  The Jupyter notebook \n",
    "\n",
    "Jupyter is a web application allowing to create and share documents named _notebooks_ (such as the present `intro-supervised-classif.ipynb` file), that can contain: 1/ explanatory text formatted in simple markdown, and equations; 2/ modifiable code that can be executed directly in the web page, with resulting output and visualization appearing directly on the page, just below the code cell.\n",
    "\n",
    "A few information about use of Jupyter notebooks:\n",
    "* A notebook is structured in editable blocks called _cells_. A cell can contain _raw text_, code, or markdown-formatted text. For more information on markdown syntax, you can read the following [guide](http://jupyter-notebook.readthedocs.io/en/latest/examples/Notebook/Working%20With%20Markdown%20Cells.html) !\n",
    "* To execute a cell, just click on it to select it, and then type the Shift+Enter shortcut (or use the Play button in the menu bar).\n",
    "* To create a new empty cell below the currently selected one, type the Alt+Enter shortcut (or use the \"+\" button on the menu bar).\n",
    "* The Insert menu also allows to insert a new cell either below or above the currently selected one. \n",
    "* In case the notebook is frozen (i.e. stops responding to commands), you can restart it either by pressing the Restart button or using the Kernel --> Restart menu.\n",
    "\n",
    "A few elements about using Jupyter notebooks containing Python code:\n",
    "* A Python code cell behaves like an interactive Python shell (more precisely like ipython, on which Jupyter is based). In particular: \n",
    "  * The tabulation key performs auto-completion of the keyword you have begun to type\n",
    "  * Typing a question mark after the name of an object loads and and displays interactive help for this function.\n",
    "* Jupyter includes special Python commands called _magics_. For example, `%bash` allows to execute bash code as if you were in a linux terminal, `%paste` allows to paste a code block that had been copied before (from the notebook or another application) while respecting its formatting (in particular indentations), and `%matplotlib inline` allows to display matplotlib graphic visualisations _inside the notebook_ instead of an external window. A complete list of _magics_ can be found at http://ipython.readthedocs.io/en/stable/interactive/magics.html \n",
    "\n",
    "\n",
    "### Ressources \n",
    "* To know more about interactive Python shell python: http://ipython.readthedocs.io/en/stable/interactive/tutorial.html\n",
    "* To know more about Jupyter : https://jupyter.org/\n",
    "* Python and Python Scientifique : http://www.scipy-lectures.org/\n",
    "* For a quick introduction to difference between python shell, interactive python shell, and notebooks: https://www.youtube.com/watch?v=ULzWaZQa1Dc (in French)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation of classic computation and visualization packages \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This practical aims at familiarizing you with scikit-learn, and learn to use models contained in this library.\n",
    "\n",
    "We will use a simplified version (called _digits_) of the classic MNIST dataset. Each exampl of this dataset is a handwritten digit in low resolution (`8x8`images).\n",
    "Let's import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "[0 1 2 ... 8 9 8]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "print(digits.data.shape)\n",
    "print(digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `data` attribute of an sklearn dataset systematically has the following dimensions: `(n_samples, n_features)`.\n",
    "Here, one line is therefore a vector corresponding to a \"flattened\" image. This image can be visualized after restructuring the vector with the `.reshape` method of a numpy table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of the 16 first examples of the dataset.\n",
    "for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i+1)\n",
    "    ax.imshow(digits.data[i,:].reshape((8,8)), cmap='Greys')\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data` and `target` are 2 attributes of this dataset.\n",
    "It is possible to list the attributes and methods of class using `dir(object)`.\n",
    "\n",
    "**Question:**\n",
    "\n",
    "> Was there a simpler way to plot the example images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here will be to learn to classify these images according to the digit they represent (therefore 10 classes).\n",
    "\n",
    "For evaluating the learnt classifier, it is **essential to use a TEST dataset INDEPENDANT from the one used for training**.\n",
    "Randomly separating a dataset into a `train` part and a `test` part can be done using [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test, label_train, label_test = train_test_split(digits.data, digits.target, \n",
    "                                                                    test_size=0.3, random_state=84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'train labels')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(label_test)\n",
    "plt.xlabel('test labels')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(label_train)\n",
    "plt.xlabel('train labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the splitting is done totally randomly and the dataset is not large enough, this can produce uneven label repartition inside `test` and `train`. \n",
    "This can affect the performances of learnt models. For avoiding this, it is necessary to split tha dataset in a way that ensures in `train` and `test` the same proportions of labels as in the original full dataset: this is called _stratification_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test, label_train, label_test = train_test_split(digits.data, digits.target, \n",
    "                                                                    test_size=0.3, random_state=84, stratify=digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'train labels')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(label_test)\n",
    "plt.xlabel('test labels')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(label_train)\n",
    "plt.xlabel('train labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training of a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train a model on the training set (`data_train`, `label_train`), and then evaluate it on the test dataset (`data_test`, `label_test`).\n",
    "\n",
    "In sklearn, all models are implemented as subclasses of `BaseEstimator`.\n",
    "They are all used in the same manner, in the 3 following steps:\n",
    "\n",
    "* Instantiate the model `model(**kwargs)`\n",
    "* Learn the model on a training set with the `fit` method: `model.fit(X=data, y=ground_truth)`.\n",
    "* Use and evaluate the trained model with `predict` and `score` methods. For example: `model.predict(X=data_test)`\n",
    "\n",
    "Reminder: `dir(object)` can be used to list the available methods and attributes, and `help(object.method)` displays the documentation of the corresponding method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 1: Instantiate, train, and test a 5-Nearest-Neighbors classifier on the digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "## Instantiate, train, and test a 5-nearest-neighbors (5-NN) classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look in more details at some examples of successes and failures of the obtained 5-NN classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_13764/322366827.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\fabien\\AppData\\Local\\Temp/ipykernel_13764/322366827.py\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    preds =\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(84)\n",
    "## Instantiate `preds` with the predictions of the 5-NN classifier on the test set\n",
    "preds = \n",
    "\n",
    "success = np.array(preds) == np.array(label_test)   \n",
    "\n",
    "# Some example of correct predictions:\n",
    "data_s, pred_s, label_s =data_test[success,:], preds[success], label_test[success]\n",
    "sample = np.random.choice(len(pred_s), size=16) # Echantillon aléatoire de 16 succès\n",
    "plt.figure(figsize=(7, 7))\n",
    "for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i+1)\n",
    "    pred, ground_truth = pred_s[sample][i], label_s[sample][i]\n",
    "    ax.imshow(data_s[sample,:][i,:].reshape((8,8)), cmap='Greys')\n",
    "    ax.set_title('Pred: {}, Label: {}'.format(pred, ground_truth), color='b')\n",
    "    ax.set_axis_off()\n",
    "\n",
    "# Some example of FALSE predictions:\n",
    "data_f, pred_f, label_f =data_test[~success,:], preds[~success], label_test[~success]\n",
    "sample = np.random.choice(len(pred_f),size=16)\n",
    "plt.figure(figsize=(7, 7))\n",
    "for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i+1)\n",
    "    pred, ground_truth = pred_f[sample][i], label_f[sample][i]\n",
    "    ax.imshow(data_f[sample,:][i,:].reshape((8,8)), cmap='Greys')\n",
    "    ax.set_title('Pred: {}, Label: {}'.format(pred, ground_truth), color='r')\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2: Train and evaluate a regularized logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to create to create _execution pipelines_ using `sklearn.pipeline.Pipeline`.\n",
    "As any other model, a _pipeline_ has `fit`, `predict`, (etc...), methods.\n",
    "\n",
    "Now let's implement a regularized logistic regression, using regularization parameter $\\frac{1}{C} = \\frac{1}{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "C = 2\n",
    "penalty='l2'\n",
    "lreg = LogisticRegression(penalty=penalty, C=C, max_iter=200)\n",
    "pip = Pipeline([('scaler', StandardScaler()), ('lreg', lreg)])\n",
    "\n",
    "# Train and test the regularized logistic regression (preceded by a normalization of input data):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation of a classifier\n",
    "\n",
    "All sklearn classifiers have a `score` method, but it computes only the **average** `accuracy` on a dataset. This is not sufficiently detailed, as it could hide a quasi-perfect accuracy on some classes combined with very poor accuracy on other classes. \n",
    "\n",
    "Many other metrics available for evaluation of classifiers, as well as for other tasks such as regression or clustering.\n",
    "In order to quantitatively evaluate the detailed performances of a model, the [`metrics`](https://scikit-learn.org/stable/modules/model_evaluation.html) module of sklearn can be used.\n",
    "It contains several useful pre-implemented metrics: [`accuracy`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score), [`f1_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score), [`auc_roc`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "acc = metrics.accuracy_score(y_true=label_test, y_pred=preds)\n",
    "f1_weighted = metrics.f1_score(label_test, preds, average='weighted')\n",
    "print('Accuracy : {}, f1 : {}'.format(acc, f1_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification report provides a synthetic view of the performances of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = metrics.classification_report(y_true=label_test, y_pred=preds)\n",
    "print(report)\n",
    "\n",
    "## Il est possible de générer un dictionnaire des performances :\n",
    "## report_dict = metrics.classification_report(y_true=label_test, y_pred=preds, output_dict=True)\n",
    "## On accède alors aux performances concernant le label 0 par report_dict['0']."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction performances of a classifier can be visualized with a _confusion matrix_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "cm = metrics.confusion_matrix(y_true=label_test, y_pred=preds)\n",
    "ax = sns.heatmap(cm, cmap='coolwarm', annot=cm)\n",
    "ax.set_xlabel('True label')\n",
    "ax.set_ylabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3: Plot the confusion matrix of the regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix of the regularized logistic regression\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Visualization of predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing predictions in input space is difficult for input dimension > 2.\n",
    "One possible workaround is to use reduction dimension such as PCA, either directly on input space before training, or only in the visualization step (to avoid loosing information before training).\n",
    "Below, we illustrate the first case: we replace the input images (8x8 pixels) by the first 2 principal componants of the dataset. We then train a k-NN classifier on this reduced-dimension inputs, and can therefore easily plot predictions for any point in this reduced 2D input space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# We compute the first 2 PCA componants of the original dataset, and then project each example on this 2D space\n",
    "pca = PCA(n_components=2, whiten=True)\n",
    "X = pca.fit_transform(data_train)\n",
    "\n",
    "# We then train a 1-NN classifier on the projected dataset\n",
    "knnc = KNeighborsClassifier(n_neighbors=1)\n",
    "knnc.fit(X=X, y=label_train)\n",
    "\n",
    "## For visualizing the predictions of the 1-NN classifier, \n",
    "## we compute predictions on a rather dense set of points in the 2D space,\n",
    "## and color these points depending on the predicted class\n",
    "\n",
    "h = .02  # Defines the grid resolution\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "cmap = plt.cm.get_cmap('magma', 10)\n",
    "Z = knnc.predict(np.c_[xx.ravel(), yy.ravel()]) # Prédiction d'un ensemble de points du plan des composantes principales.\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(figsize=(10,10))\n",
    "im=plt.pcolormesh(xx, yy, Z, cmap='magma',alpha=.8)\n",
    "plt.legend([mpatches.Patch(color=cmap(l)) for l in range(10)], [str(l) for l in range(10)])\n",
    "\n",
    "# On affiche un échantillon des points du jeu d'entrainement\n",
    "sample = np.random.choice(X.shape[0], size=250)\n",
    "plt.scatter(X[sample, 0], X[sample, 1], c=label_train[sample], cmap='magma', edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now also visualize the effect of the `n_neighbors` hyper-parameter on predictions of the k-NN classifier obtained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "# On va afficher les prédictions du plan des composantes principales en fonction de n_neighbors.\n",
    "for o,k in enumerate([1, 5, 20, 50], 1):\n",
    "    knnc = KNeighborsClassifier(n_neighbors=k)\n",
    "    knnc.fit(X=X, y=label_train)\n",
    "    Z = knnc.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax = plt.subplot(2, 2, o)\n",
    "    ax.pcolormesh(xx, yy, Z, cmap='magma',alpha=.8, shading='auto')\n",
    "    ax.set_title('k = {}'.format(k))\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "\n",
    "> What is the hypothesis class of the 1-Nearest-Neighbor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 4: Visualize the impact of the $C$ regularization hyper-parameter on predictions obtained with regularized logistic regression ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "# Train the regularized logistic regression on the 2D-PCA input space, for several values of C\n",
    "#  and plot the corresponding predictions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "> What do you observe? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all types of Machine-Learning models, there is nearly always one or several hyper-parameters that can significantly impact the performance of the trained model. Just like `n_neighbors` for the k-Nearest-Neighbors model, or the `C` hyper-parameter for regularized logistic regression.\n",
    "\n",
    "It is therefore essential not only to visually inspect the impact as above, but to actually find the BEST VALUES for these crucial hyper-parameters. This can be done for instance using a `grid search`: brute-force test of a list (or `grid` if there are several hyper-parameters) of values. The ultimate goal is to maximize the generalization performance, but the selection of the best value should NOT be done directly on the test set, in order to avoid overfitting of hyper-parameter values. The model selection therefore has to be done either on a 3rd dataset dedicated to validation, or by using `cross-validation`:\n",
    "\n",
    "![](crossval.001.jpeg)\n",
    "\n",
    "In practice in sklearn, model selection using cross-validation is typically done using [`sklearn.model_selection.GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "`GridSearchCV` works as all estimators of sklearn: it has first to be instantiated, and then it is run by using its `fit` method.\n",
    "\n",
    "The main parameters of GridSearchCV are:\n",
    "\n",
    "* `estimator` : the classification model used\n",
    "* `param_grid` : dictionnary of the hyper-parameter values to be tested. The keys of this dictionnary are of type `str`, and correspond to the name of the parameter to be used for instatiating the `estimator`\n",
    "* `scoring`: defines which metric is used to select the best values for hyper-parameters.\n",
    "* `cv`: define sthe number of folds for the cross-validation\n",
    "\n",
    "Finding good values for hyper-parameters is a kind of learning (in the sense of tuning a parameter for optimizing some criteria). For this reason, model selection has to be performed on a VALIDATION set different from the final TEST set which should be used only for estimating future generalization performance of the final model. In case validation is done by cross-validation rather than by a separate validation set, _the cross-validation must therfore be performed **on the `data_train`**_.\n",
    "\n",
    "Once the `GridSearchCV` is fitted, its results can be accessed through its `.cv_results_`attribute. And its methods `score` and `predict` are respctively evaluating and using the best model found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 5: Find the best value for the `n_neighbors` hyper-parameter of k-NN model on digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## Using GridSearchCV, find the best value of hyper-parameter n_neighbors for k-NearestNeighbors applied to digits\n",
    "##   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display or plot in some way the influence of n_neighbors hyper-parameter on the k-NN model performance \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 6: Find the best value for the `C` hyper-parameter of regularized logistic regression on digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "stsc = StandardScaler()\n",
    "data_train = stsc.fit_transform(data_train)\n",
    "\n",
    "## Find the best value for hyper-parameter C of regularized logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display or plot in some way the influence on performances of C hyper-parameter for regularized logistic regression applied to digits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:** \n",
    "> Explain the respective effects of these 2 hyper-parameters on the training outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 7: Determine which model should better be used on the digits dataset, between k-NN and regularized logistic regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    "\n",
    "> How should we do to compare these 2 model types and select one? \\\n",
    "> How should we evaluate the final result of this best model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code below for selection and final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
